{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAJAMAR_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xEP9zYu_zyf",
        "outputId": "5a001648-6746-4c47-fef3-bd3b63543fe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "import requests \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from xgboost.sklearn import XGBRegressor\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Informe tècnic/cajamar/DF.csv')"
      ],
      "metadata": {
        "id": "02btNKtCAwEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización del DataFrame final\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "r4uZHoSaRQaV",
        "outputId": "604dd29c-821c-4a7d-e89f-dfccc8ef4a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         TIMESTAMP    ID    READING  DELTA\n",
              "0       2019-02-01     0  7963359.0  243.0\n",
              "1       2019-02-02     0  7969096.0  236.0\n",
              "2       2019-02-03     0  7975263.0  335.0\n",
              "3       2019-02-04     0  7982426.0  252.0\n",
              "4       2019-02-05     0  7988972.0  220.0\n",
              "...            ...   ...        ...    ...\n",
              "890826  2019-08-03  2748  1627386.0  313.0\n",
              "890827  2019-09-14  2748  1690044.0    8.0\n",
              "890828  2019-08-06  2749   627196.0    0.0\n",
              "890829  2019-10-11  2749   658022.0    2.0\n",
              "890830  2019-04-06  2756  1399044.0   12.0\n",
              "\n",
              "[890831 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed567c3c-4d81-4863-a890-d21395856335\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TIMESTAMP</th>\n",
              "      <th>ID</th>\n",
              "      <th>READING</th>\n",
              "      <th>DELTA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-02-01</td>\n",
              "      <td>0</td>\n",
              "      <td>7963359.0</td>\n",
              "      <td>243.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-02-02</td>\n",
              "      <td>0</td>\n",
              "      <td>7969096.0</td>\n",
              "      <td>236.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-02-03</td>\n",
              "      <td>0</td>\n",
              "      <td>7975263.0</td>\n",
              "      <td>335.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-02-04</td>\n",
              "      <td>0</td>\n",
              "      <td>7982426.0</td>\n",
              "      <td>252.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-02-05</td>\n",
              "      <td>0</td>\n",
              "      <td>7988972.0</td>\n",
              "      <td>220.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890826</th>\n",
              "      <td>2019-08-03</td>\n",
              "      <td>2748</td>\n",
              "      <td>1627386.0</td>\n",
              "      <td>313.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890827</th>\n",
              "      <td>2019-09-14</td>\n",
              "      <td>2748</td>\n",
              "      <td>1690044.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890828</th>\n",
              "      <td>2019-08-06</td>\n",
              "      <td>2749</td>\n",
              "      <td>627196.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890829</th>\n",
              "      <td>2019-10-11</td>\n",
              "      <td>2749</td>\n",
              "      <td>658022.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890830</th>\n",
              "      <td>2019-04-06</td>\n",
              "      <td>2756</td>\n",
              "      <td>1399044.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>890831 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed567c3c-4d81-4863-a890-d21395856335')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed567c3c-4d81-4863-a890-d21395856335 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed567c3c-4d81-4863-a890-d21395856335');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['TIMESTAMP']=pd.to_datetime(df['TIMESTAMP'])\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXLIP7W-byBA",
        "outputId": "318f5588-6fee-46e6-90d2-dfc0b42ab991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 890831 entries, 0 to 890830\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count   Dtype         \n",
            "---  ------     --------------   -----         \n",
            " 0   TIMESTAMP  890831 non-null  datetime64[ns]\n",
            " 1   ID         890831 non-null  int64         \n",
            " 2   READING    890831 non-null  float64       \n",
            " 3   DELTA      890831 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(2), int64(1)\n",
            "memory usage: 27.2 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def missing_elements(L):\n",
        "    start, end = L[0], L[-1]\n",
        "    return sorted(set(range(start, end + 1)).difference(L))\n",
        "missing_elements(list(df[\"ID\"].unique().astype(int)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nT2VhsGVx0P",
        "outputId": "8b3f1f35-4240-4c83-bd24-b6b80250f572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2726, 2738, 2740, 2741, 2750, 2751, 2752, 2753, 2754, 2755]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "!pip install skforecast\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
        "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
        "from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
        "from skforecast.model_selection import grid_search_forecaster\n",
        "from skforecast.model_selection import backtesting_forecaster\n",
        "\n",
        "from joblib import dump, load"
      ],
      "metadata": {
        "id": "RHUdyLJVz1BT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "outputId": "31494ad5-340d-4b1e-9916-d0a9fbec84ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.4-cp37-none-manylinux1_x86_64.whl (76.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.1 MB 52 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.4\n",
            "Collecting skforecast\n",
            "  Downloading skforecast-0.4.3-py2.py3-none-any.whl (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<=1.4,>=1.2 in /usr/local/lib/python3.7/dist-packages (from skforecast) (1.3.5)\n",
            "Requirement already satisfied: numpy<=1.22,>=1.20 in /usr/local/lib/python3.7/dist-packages (from skforecast) (1.21.5)\n",
            "Collecting statsmodels<=0.13,>=0.12\n",
            "  Downloading statsmodels-0.13.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 41.2 MB/s \n",
            "\u001b[?25hCollecting tqdm<=4.62,>=4.57.0\n",
            "  Downloading tqdm-4.62.0-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.7/dist-packages (from skforecast) (1.0.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.4,>=1.2->skforecast) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.4,>=1.2->skforecast) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas<=1.4,>=1.2->skforecast) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->skforecast) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->skforecast) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->skforecast) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels<=0.13,>=0.12->skforecast) (0.5.2)\n",
            "Installing collected packages: tqdm, statsmodels, skforecast\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.63.0\n",
            "    Uninstalling tqdm-4.63.0:\n",
            "      Successfully uninstalled tqdm-4.63.0\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "Successfully installed skforecast-0.4.3 statsmodels-0.13.0 tqdm-4.62.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "statsmodels"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# Funciones necesarias para el preprocesado final de cada id\n",
        "\n",
        "def fill_na_0(df):\n",
        "  return df.fillna(0)\n",
        "\n",
        "def fill_na_custom(df):\n",
        "  return df.interpolate(method='piecewise_polynomial', axis=0).ffill().bfill()\n",
        "\n",
        "def filter_outliers(df):\n",
        "  lof = LocalOutlierFactor(contamination=0.05, n_neighbors=7)\n",
        "  indx = lof.fit_predict(df) \n",
        "  mask = indx == 1\n",
        "  df_test = df[mask]\n",
        "  return df_test\n",
        "\n",
        "def fill_na_mean_adj(df):\n",
        "   return (df.ffill()+df.bfill())/2\n"
      ],
      "metadata": {
        "id": "gsf12BEfnrCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pp_train_4_pred(train,id):\n",
        "  date_index = pd.date_range('2019-02-1', periods=365, freq='D')\n",
        "  train.set_index('TIMESTAMP', inplace=True)\n",
        "  train = train.asfreq('D')\n",
        "  train=train.reindex(date_index)\n",
        "  if(train['DELTA'].isna().sum()>=364):\n",
        "    train = fill_na_0(train)\n",
        "  else:\n",
        "    train = fill_na_custom(train)\n",
        "    train = fill_na_0(train)\n",
        "    train = filter_outliers(train)\n",
        "    train = train.asfreq('D')\n",
        "    train=train.reindex(date_index)\n",
        "    train = fill_na_mean_adj(train)\n",
        "    train = fill_na_custom(train)\n",
        "  return train\n",
        "\n",
        "def pp_train_4_pred2(train,id,periods):\n",
        "  date_index = pd.date_range('2019-02-1', periods=periods, freq='D')\n",
        "  train.set_index('TIMESTAMP', inplace=True)\n",
        "  train = train.asfreq('D')\n",
        "  train=train.reindex(date_index)\n",
        "  if(train['DELTA'].isna().sum()<364):\n",
        "    for item,frame in train[\"DELTA\"].iteritems():\n",
        "      if(pd.isnull(frame)):\n",
        "        train.loc[item][\"ID\"]=id\n",
        "        loc = train.index.get_loc(item)\n",
        "        train.loc[item][\"READING\"]=train.iloc[loc - 1][\"READING\"]\n",
        "        for i in range(int(len(list(train.index))/14)):\n",
        "          if((loc - i*7)>0 and (loc + i*7)<periods):\n",
        "            if(not np.isnan(train.iloc[loc - i*7][\"DELTA\"]) and not np.isnan(train.iloc[loc + i*7][\"DELTA\"])):\n",
        "              train.loc[item][\"DELTA\"]=(train.iloc[loc - i*7][\"DELTA\"]+train.iloc[loc + i*7][\"DELTA\"])/2\n",
        "              break\n",
        "        if(np.isnan(train.iloc[loc][\"DELTA\"])):\n",
        "          mean=[]\n",
        "          for i in range(8):\n",
        "            if((loc - i*7)>0 and (loc + i*7)<periods):\n",
        "              if(not np.isnan(train.iloc[loc - i*7][\"DELTA\"])):\n",
        "                  mean.append(train.iloc[loc - i*7][\"DELTA\"])\n",
        "              elif(not np.isnan(train.iloc[loc + i*7][\"DELTA\"])):\n",
        "                  mean.append(train.iloc[loc - i*7][\"DELTA\"]) \n",
        "          if(len(mean)>0):\n",
        "            train.loc[item][\"DELTA\"]=sum(mean)/len(mean)\n",
        "    train = fill_na_custom(train)\n",
        "    train = filter_outliers(train)\n",
        "    train = train.asfreq('D')\n",
        "    train = train.reindex(date_index)\n",
        "    train = fill_na_mean_adj(train)\n",
        "    train = fill_na_custom(train)\n",
        "  else:\n",
        "    train = fill_na_0(train)\n",
        "  return train\n"
      ],
      "metadata": {
        "id": "hHKQwPgtsfFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtención del dataset de predicciones de febrero de 2020 para la partición 1\n",
        "\n",
        "# NOTA: la ejecución de esta celda es bastante costosa.\n",
        "\n",
        "df_output = pd.DataFrame()\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "llista_id = df[\"ID\"].unique()\n",
        "for id in llista_id[:344]:\n",
        "    print(\"----------------\")\n",
        "    print(\"ID:\",id)\n",
        "    train=df[df[\"ID\"]==id]\n",
        "    train = pp_train_4_pred2(train,id,365)\n",
        "    forecaster = ForecasterAutoreg(\n",
        "                    regressor = RandomForestRegressor(n_estimators=30,random_state=0),\n",
        "                    lags      = 12,\n",
        "                 )\n",
        "    param_grid = {}\n",
        "    lags_grid = {7,14,21,28,35,42,49,56}\n",
        "    results_grid = grid_search_forecaster(\n",
        "                                forecaster         = forecaster,\n",
        "                                y                  = train['DELTA'],\n",
        "                                param_grid         = param_grid,\n",
        "                                lags_grid          = lags_grid,\n",
        "                                steps              = 5,\n",
        "                                refit              = True,\n",
        "                                metric             = 'mean_squared_error',\n",
        "                                initial_train_size = int(len(train)*0.5),\n",
        "                                return_best        = True,\n",
        "                                verbose            = False\n",
        "                          )\n",
        "    forecaster.fit(y = train[\"DELTA\"])\n",
        "    predictions =(forecaster.predict(steps=20))\n",
        "    row = {\"ID\":id,\"1\":round(predictions.values[0],2),\"2\":round(predictions.values[1],2),\"3\":round(predictions.values[2],2),\"4\":round(predictions.values[3],2),\"5\":round(predictions.values[4],2),\"6\":round(predictions.values[5],2),\"7\":round(predictions.values[6],2),\"Suma1\":round(sum(predictions.values[0:7]),2),\"Suma2\":round(sum(predictions.values[7:14]))}\n",
        "    df_output = df_output.append(row, ignore_index=True)\n",
        "\n",
        "df_output.ID = df_output.ID.astype(int)\n",
        "df_output.to_csv('Part1.txt', header=False, index=False, sep=\"|\")"
      ],
      "metadata": {
        "id": "FowZdMfcmeOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtención del dataset de predicciones de febrero de 2020 para la partición 2\n",
        "\n",
        "# NOTA: la ejecución de esta celda es bastante costosa.\n",
        "\n",
        "df_output = pd.DataFrame()\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "llista_id = df[\"ID\"].unique()\n",
        "for id in llista_id[344:688]:\n",
        "    print(\"----------------\")\n",
        "    print(\"ID:\",id)\n",
        "    train=df[df[\"ID\"]==id]\n",
        "    train = pp_train_4_pred2(train,id,365)\n",
        "    forecaster = ForecasterAutoreg(\n",
        "                    regressor = RandomForestRegressor(n_estimators=30,random_state=0),\n",
        "                    lags      = 12,\n",
        "                 )\n",
        "    param_grid = {}\n",
        "    lags_grid = {7,14,21,28,35,42,49,56}\n",
        "    results_grid = grid_search_forecaster(\n",
        "                                forecaster         = forecaster,\n",
        "                                y                  = train['DELTA'],\n",
        "                                param_grid         = param_grid,\n",
        "                                lags_grid          = lags_grid,\n",
        "                                steps              = 5,\n",
        "                                refit              = True,\n",
        "                                metric             = 'mean_squared_error',\n",
        "                                initial_train_size = int(len(train)*0.5),\n",
        "                                return_best        = True,\n",
        "                                verbose            = False\n",
        "                          )\n",
        "    forecaster.fit(y = train[\"DELTA\"])\n",
        "    predictions =(forecaster.predict(steps=20))\n",
        "    row = {\"ID\":id,\"1\":round(predictions.values[0],2),\"2\":round(predictions.values[1],2),\"3\":round(predictions.values[2],2),\"4\":round(predictions.values[3],2),\"5\":round(predictions.values[4],2),\"6\":round(predictions.values[5],2),\"7\":round(predictions.values[6],2),\"Suma1\":round(sum(predictions.values[0:7]),2),\"Suma2\":round(sum(predictions.values[7:14]))}\n",
        "    df_output = df_output.append(row, ignore_index=True)\n",
        "\n",
        "df_output.ID = df_output.ID.astype(int)\n",
        "df_output.to_csv('Part2.txt', header=False, index=False, sep=\"|\")"
      ],
      "metadata": {
        "id": "dDIGwY9nMnvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtención del dataset de predicciones de febrero de 2020 para la partición 3\n",
        "\n",
        "# NOTA: la ejecución de esta celda es bastante costosa.\n",
        "\n",
        "df_output = pd.DataFrame()\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "llista_id = df[\"ID\"].unique()\n",
        "for id in llista_id[688:1032]:\n",
        "    print(\"----------------\")\n",
        "    print(\"ID:\",id)\n",
        "    train=df[df[\"ID\"]==id]\n",
        "    train = pp_train_4_pred2(train,id,365)\n",
        "    forecaster = ForecasterAutoreg(\n",
        "                    regressor = RandomForestRegressor(n_estimators=30,random_state=0),\n",
        "                    lags      = 12,\n",
        "                 )\n",
        "    param_grid = {}\n",
        "    lags_grid = {7,14,21,28,35,42,49,56}\n",
        "    results_grid = grid_search_forecaster(\n",
        "                                forecaster         = forecaster,\n",
        "                                y                  = train['DELTA'],\n",
        "                                param_grid         = param_grid,\n",
        "                                lags_grid          = lags_grid,\n",
        "                                steps              = 5,\n",
        "                                refit              = True,\n",
        "                                metric             = 'mean_squared_error',\n",
        "                                initial_train_size = int(len(train)*0.5),\n",
        "                                return_best        = True,\n",
        "                                verbose            = False\n",
        "                          )\n",
        "    forecaster.fit(y = train[\"DELTA\"])\n",
        "    predictions =(forecaster.predict(steps=20))\n",
        "    row = {\"ID\":id,\"1\":round(predictions.values[0],2),\"2\":round(predictions.values[1],2),\"3\":round(predictions.values[2],2),\"4\":round(predictions.values[3],2),\"5\":round(predictions.values[4],2),\"6\":round(predictions.values[5],2),\"7\":round(predictions.values[6],2),\"Suma1\":round(sum(predictions.values[0:7]),2),\"Suma2\":round(sum(predictions.values[7:14]))}\n",
        "    df_output = df_output.append(row, ignore_index=True)\n",
        "\n",
        "df_output.ID = df_output.ID.astype(int)\n",
        "df_output.to_csv('Part3.txt', header=False, index=False, sep=\"|\")"
      ],
      "metadata": {
        "id": "YrqX_cnZMn2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtención del dataset de predicciones de febrero de 2020 para la partición 4\n",
        "\n",
        "# NOTA: la ejecución de esta celda es bastante costosa.\n",
        "\n",
        "df_output = pd.DataFrame()\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "llista_id = df[\"ID\"].unique()\n",
        "for id in llista_id[1032:1376]:\n",
        "    print(\"----------------\")\n",
        "    print(\"ID:\",id)\n",
        "    train=df[df[\"ID\"]==id]\n",
        "    train = pp_train_4_pred2(train,id,365)\n",
        "    forecaster = ForecasterAutoreg(\n",
        "                    regressor = RandomForestRegressor(n_estimators=30,random_state=0),\n",
        "                    lags      = 12,\n",
        "                 )\n",
        "    param_grid = {}\n",
        "    lags_grid = {7,14,21,28,35,42,49,56}\n",
        "    results_grid = grid_search_forecaster(\n",
        "                                forecaster         = forecaster,\n",
        "                                y                  = train['DELTA'],\n",
        "                                param_grid         = param_grid,\n",
        "                                lags_grid          = lags_grid,\n",
        "                                steps              = 5,\n",
        "                                refit              = True,\n",
        "                                metric             = 'mean_squared_error',\n",
        "                                initial_train_size = int(len(train)*0.5),\n",
        "                                return_best        = True,\n",
        "                                verbose            = False\n",
        "                          )\n",
        "    forecaster.fit(y = train[\"DELTA\"])\n",
        "    predictions =(forecaster.predict(steps=20))\n",
        "    row = {\"ID\":id,\"1\":round(predictions.values[0],2),\"2\":round(predictions.values[1],2),\"3\":round(predictions.values[2],2),\"4\":round(predictions.values[3],2),\"5\":round(predictions.values[4],2),\"6\":round(predictions.values[5],2),\"7\":round(predictions.values[6],2),\"Suma1\":round(sum(predictions.values[0:7]),2),\"Suma2\":round(sum(predictions.values[7:14]))}\n",
        "    df_output = df_output.append(row, ignore_index=True)\n",
        "\n",
        "df_output.ID = df_output.ID.astype(int)\n",
        "df_output.to_csv('Part4.txt', header=False, index=False, sep=\"|\")"
      ],
      "metadata": {
        "id": "9_DF4PNBMn8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtención del dataset de predicciones de febrero de 2020 para la partición 5\n",
        "\n",
        "# NOTA: la ejecución de esta celda es bastante costosa.\n",
        "\n",
        "df_output = pd.DataFrame()\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "llista_id = df[\"ID\"].unique()\n",
        "for id in llista_id[1376:1720]:\n",
        "    print(\"----------------\")\n",
        "    print(\"ID:\",id)\n",
        "    train=df[df[\"ID\"]==id]\n",
        "    train = pp_train_4_pred2(train,id,365)\n",
        "    forecaster = ForecasterAutoreg(\n",
        "                    regressor = RandomForestRegressor(n_estimators=30,random_state=0),\n",
        "                    lags      = 12,\n",
        "                 )\n",
        "    param_grid = {}\n",
        "    lags_grid = {7,14,21,28,35,42,49,56}\n",
        "    results_grid = grid_search_forecaster(\n",
        "                                forecaster         = forecaster,\n",
        "                                y                  = train['DELTA'],\n",
        "                                param_grid         = param_grid,\n",
        "                                lags_grid          = lags_grid,\n",
        "                                steps              = 5,\n",
        "                                refit              = True,\n",
        "                                metric             = 'mean_squared_error',\n",
        "                                initial_train_size = int(len(train)*0.5),\n",
        "                                return_best        = True,\n",
        "                                verbose            = False\n",
        "                          )\n",
        "    forecaster.fit(y = train[\"DELTA\"])\n",
        "    predictions =(forecaster.predict(steps=20))\n",
        "    row = {\"ID\":id,\"1\":round(predictions.values[0],2),\"2\":round(predictions.values[1],2),\"3\":round(predictions.values[2],2),\"4\":round(predictions.values[3],2),\"5\":round(predictions.values[4],2),\"6\":round(predictions.values[5],2),\"7\":round(predictions.values[6],2),\"Suma1\":round(sum(predictions.values[0:7]),2),\"Suma2\":round(sum(predictions.values[7:14]))}\n",
        "    df_output = df_output.append(row, ignore_index=True)\n",
        "\n",
        "df_output.ID = df_output.ID.astype(int)\n",
        "df_output.to_csv('Part5.txt', header=False, index=False, sep=\"|\")"
      ],
      "metadata": {
        "id": "DJ5DUqkLMoCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtención del dataset de predicciones de febrero de 2020 para la partición 6\n",
        "\n",
        "# NOTA: la ejecución de esta celda es bastante costosa.\n",
        "\n",
        "df_output = pd.DataFrame()\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "llista_id = df[\"ID\"].unique()\n",
        "for id in llista_id[1720:2064]:\n",
        "    print(\"----------------\")\n",
        "    print(\"ID:\",id)\n",
        "    train=df[df[\"ID\"]==id]\n",
        "    train = pp_train_4_pred2(train,id,365)\n",
        "    forecaster = ForecasterAutoreg(\n",
        "                    regressor = RandomForestRegressor(n_estimators=30,random_state=0),\n",
        "                    lags      = 12,\n",
        "                 )\n",
        "    param_grid = {}\n",
        "    lags_grid = {7,14,21,28,35,42,49,56}\n",
        "    results_grid = grid_search_forecaster(\n",
        "                                forecaster         = forecaster,\n",
        "                                y                  = train['DELTA'],\n",
        "                                param_grid         = param_grid,\n",
        "                                lags_grid          = lags_grid,\n",
        "                                steps              = 5,\n",
        "                                refit              = True,\n",
        "                                metric             = 'mean_squared_error',\n",
        "                                initial_train_size = int(len(train)*0.5),\n",
        "                                return_best        = True,\n",
        "                                verbose            = False\n",
        "                          )\n",
        "    forecaster.fit(y = train[\"DELTA\"])\n",
        "    predictions =(forecaster.predict(steps=20))\n",
        "    row = {\"ID\":id,\"1\":round(predictions.values[0],2),\"2\":round(predictions.values[1],2),\"3\":round(predictions.values[2],2),\"4\":round(predictions.values[3],2),\"5\":round(predictions.values[4],2),\"6\":round(predictions.values[5],2),\"7\":round(predictions.values[6],2),\"Suma1\":round(sum(predictions.values[0:7]),2),\"Suma2\":round(sum(predictions.values[7:14]))}\n",
        "    df_output = df_output.append(row, ignore_index=True)\n",
        "\n",
        "df_output.ID = df_output.ID.astype(int)\n",
        "df_output.to_csv('Part6.txt', header=False, index=False, sep=\"|\")"
      ],
      "metadata": {
        "id": "4JX3pK_uMoIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtención del dataset de predicciones de febrero de 2020 para la partición 7\n",
        "\n",
        "# NOTA: la ejecución de esta celda es bastante costosa.\n",
        "\n",
        "df_output = pd.DataFrame()\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "llista_id = df[\"ID\"].unique()\n",
        "for id in llista_id[2064:2408]:\n",
        "    print(\"----------------\")\n",
        "    print(\"ID:\",id)\n",
        "    train=df[df[\"ID\"]==id]\n",
        "    train = pp_train_4_pred2(train,id,365)\n",
        "    forecaster = ForecasterAutoreg(\n",
        "                    regressor = make_pipeline(StandardScaler(), Ridge()),\n",
        "                    lags      = 12,\n",
        "                 )\n",
        "    param_grid = {}\n",
        "    lags_grid = {7,14,21,28,35,42,49,56}\n",
        "    results_grid = grid_search_forecaster(\n",
        "                                forecaster         = forecaster,\n",
        "                                y                  = train['DELTA'],\n",
        "                                param_grid         = param_grid,\n",
        "                                lags_grid          = lags_grid,\n",
        "                                steps              = 5,\n",
        "                                refit              = True,\n",
        "                                metric             = 'mean_squared_error',\n",
        "                                initial_train_size = int(len(train)*0.5),\n",
        "                                return_best        = True,\n",
        "                                verbose            = False\n",
        "                          )\n",
        "    forecaster.fit(y = train[\"DELTA\"])\n",
        "    predictions =(forecaster.predict(steps=20))\n",
        "    row = {\"ID\":id,\"1\":round(predictions.values[0],2),\"2\":round(predictions.values[1],2),\"3\":round(predictions.values[2],2),\"4\":round(predictions.values[3],2),\"5\":round(predictions.values[4],2),\"6\":round(predictions.values[5],2),\"7\":round(predictions.values[6],2),\"Suma1\":round(sum(predictions.values[0:7]),2),\"Suma2\":round(sum(predictions.values[7:14]))}\n",
        "    df_output = df_output.append(row, ignore_index=True)\n",
        "\n",
        "df_output.ID = df_output.ID.astype(int)\n",
        "df_output.to_csv('Part7.txt', header=False, index=False, sep=\"|\")"
      ],
      "metadata": {
        "id": "Ao674aRLMoNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtención del dataset de predicciones de febrero de 2020 para la partición 8\n",
        "\n",
        "# NOTA: la ejecución de esta celda es bastante costosa.\n",
        "\n",
        "df_output = pd.DataFrame()\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "llista_id = df[\"ID\"].unique()\n",
        "for id in llista_id[2408:]:\n",
        "    print(\"----------------\")\n",
        "    print(\"ID:\",id)\n",
        "    train=df[df[\"ID\"]==id]\n",
        "    train = pp_train_4_pred2(train,id,365)\n",
        "    forecaster = ForecasterAutoreg(\n",
        "                    regressor = make_pipeline(StandardScaler(), Ridge()),\n",
        "                    lags      = 12,\n",
        "                 )\n",
        "    param_grid = {}\n",
        "    lags_grid = {7,14,21,28,35,42,49,56}\n",
        "    results_grid = grid_search_forecaster(\n",
        "                                forecaster         = forecaster,\n",
        "                                y                  = train['DELTA'],\n",
        "                                param_grid         = param_grid,\n",
        "                                lags_grid          = lags_grid,\n",
        "                                steps              = 5,\n",
        "                                refit              = True,\n",
        "                                metric             = 'mean_squared_error',\n",
        "                                initial_train_size = int(len(train)*0.5),\n",
        "                                return_best        = True,\n",
        "                                verbose            = False\n",
        "                          )\n",
        "    forecaster.fit(y = train[\"DELTA\"])\n",
        "    predictions =(forecaster.predict(steps=20))\n",
        "    row = {\"ID\":id,\"1\":round(predictions.values[0],2),\"2\":round(predictions.values[1],2),\"3\":round(predictions.values[2],2),\"4\":round(predictions.values[3],2),\"5\":round(predictions.values[4],2),\"6\":round(predictions.values[5],2),\"7\":round(predictions.values[6],2),\"Suma1\":round(sum(predictions.values[0:7]),2),\"Suma2\":round(sum(predictions.values[7:14]))}\n",
        "    df_output = df_output.append(row, ignore_index=True)\n",
        "\n",
        "df_output.ID = df_output.ID.astype(int)\n",
        "df_output.to_csv('Part8.txt', header=False, index=False, sep=\"|\")"
      ],
      "metadata": {
        "id": "2VYFNVJ9Mof7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Juntamos las diferentes predicciones en un único fichero\n",
        "df1 = pd.read_csv('/content/Part1.txt', header=None, sep='|')\n",
        "df2 = pd.read_csv('/content/Part2.txt', header= None, sep='|')\n",
        "df3 = pd.read_csv('/content/Part3.txt', header= None, sep='|')\n",
        "df4 = pd.read_csv('/content/Part4.txt', header= None, sep='|')\n",
        "df5 = pd.read_csv('/content/Part5.txt', header= None, sep='|')\n",
        "df6 = pd.read_csv('/content/Part6.txt', header= None, sep='|')\n",
        "df7 = pd.read_csv('/content/Part7.txt', header= None, sep='|')\n",
        "df8 = pd.read_csv('/content/Part8.txt', header= None, sep='|')\n",
        "\n",
        "frames = [df1, df2, df3, df4, df5, df6, df7,df8]\n",
        "\n",
        "df_final = pd.concat(frames)\n",
        "df_final"
      ],
      "metadata": {
        "id": "LteAytJjsRJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.to_csv('OvoCAD.txt', header=False, index=False, sep=\"|\")"
      ],
      "metadata": {
        "id": "15MjE5q0s5gX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}